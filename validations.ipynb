{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0413d1a9-4f94-44d5-af96-68e98e8c153f",
   "metadata": {},
   "source": [
    "# TempEst-NEXT Validation Suite\n",
    "\n",
    "This Notebook provides a standard suite of model tests for TempEst-NEXT.  This serves two purposes:\n",
    "\n",
    "1. Reproducibility of research.  This notebook is used to generate final manuscript figures relating to model performance. The notebook itself is provided with the published model and dataset, allowing exact reproducibility (and easy modification) of the analysis.\n",
    "2. Efficient, consistent testing.  After modifying the model, running this notebook is a quick way to make sure everything still works and to assess performance impacts.\n",
    "\n",
    "For validation, we use two pre-retrieved datasets as well as some automatic retrieval of new data.  The two pre-retrieved datasets are a \"development\" set of ~900 USGS gages (nominally 1,000; 900ish with overlapping data coverage) and a \"test\" set of ~400 (nominal) USGS gages paired with daymet meteorology, 3DEP topography, NLCD land cover, etc.  The development set was used for model development and tuning, while the test set is reserved for final validation (i.e., here).\n",
    "\n",
    "## Assessed Model Characteristics\n",
    "\n",
    "The goal is to assess several model performance characteristics.  Forecasting is used for a handful of tests, but most analysis focuses on hindcasting for computational convenience.  It is assumed that any performance discrepancies in forecasting vs hindcasting would be apparent in the tests that cover both, and thus that not every analysis needs to test forecasting.\n",
    "\n",
    "In this notebook, forecasting is primarily tested by using archived weather forecasts to predict what the forecast would have been for time periods where observations are available, which is necessary for automatic testing.  There is code to run a \"real\" forecast, but this cannot be automatically evaluated because observations are not available, so the user is left to go back and check once observations are available.\n",
    "\n",
    "1. Calibrated model hindcasting and forecasting performance, using TempEst-NEWT like a typical single-watershed model\n",
    "2. General ungaged hindcasting and forecasting performance\n",
    "3. Ungaged-region hindcasting performance\n",
    "4. Ungaged-elevation hindcasting performance\n",
    "5. Ungaged-time-period hindcasting performance\n",
    "6. Disturbance hindcasting performance\n",
    "7. Small-stream hindcasting performance?\n",
    "\n",
    "## Tests\n",
    "\n",
    "The following tests are used to assess the above performance characteristics.\n",
    "\n",
    "- Calibrated testing: train a model on the first 70% of observations for each stream, then evaluate performance for predicting the last 30%.  This uses the development dataset.\n",
    "  - Use meteorology estimates (daymet) for training and testing: hindcast test.  Because the model architecture does not actually use \"today's\" weather (up through yesterday only), this is also a 24-hour forecast test.\n",
    "  - Use weather forecast archives (HRRR, GFS/GEFS) for training and testing: forecast test.  Test forecast periods of 2, 3 (HRRR), 7, 10, 14, 17 (GFS/GEFS) days.  Note forecast period is 1 day *past* the last day of the weather forecast, since NEWT does not depend on day-of weather.\n",
    "  - Use meteorology estimates for training and forecasts for testing: evaluate the impact of heterogeneous datasets.  Use 2-day HRRR-forced forecast only.\n",
    "- Gagewise cross-validation: partition development dataset gages into *k* equal sets.  Train a model on all partitions but one, and evaluate performance for predicting the excluded partition.  This tests general ungaged performance, not accounting for any potential impact of having used the same dataset for model tuning.  Hindcasting (met estimate) only.\n",
    "- Test set validation: train a model on the development set, and evaluate performance for predicting the test set.  This tests general ungaged performance for a fully-independent dataset.\n",
    "  - Meteorology estimates (hindcast)\n",
    "  - Weather forecast archives (forecast) for a range of lead times\n",
    "  - Train on estimates/test on forecasts (forecast with heterogeneous data)\n",
    "- Extrapolation hindcasting tests: partition the combined development and testing sets along some characteristic of interest, and use a model trained on one group to predict the other group.  This tests the ability of TempEst-NEXT to extrapolate in terms of specific characteristics.  All hindcasting.\n",
    "  - Regional: partition the CONUS into contiguous regions and run leave-one-out cross-validation over the regions.\n",
    "  - Elevation: train a model on the lower elevations and predict higher elevations.  Partial dependency plots and previous research suggest there is a major shift in watershed dynamics around 2300 m, and it is difficult to extrapolate past that barrier.\n",
    "  - Time (walk-forward validation): train a model up to a given year, then predict the next year.  This tests whether the model can extrapolate forward in time.\n",
    "- Regime-shift hindcasting: identify a set of watersheds for which the observed thermal regime has shifted significantly.  Train the model on everything else, then try to predict the disturbed watersheds and see how the model performs.  This assesses whether TempEst-NEXT is capable of capturing regime shifts.\n",
    "- Small-stream hindcasting: if possible, use the model to predict temperatures at very small (e.g., first-order headwaters, centimeters to a few meters wide) streams where some observations are available, just to see if it works there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e470d85-7d95-49d5-b836-5f8bb2d9a8bf",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac96a84d-dbd2-4ff2-909f-7b404cdc4efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NEXT\n",
    "import NEWT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d636d2-4aaa-4205-bb94-0a5b5f8ef31e",
   "metadata": {},
   "source": [
    "There are some major outliers that are either erroneous (negative temperatures) or wildly unrepresentative (hot springs) that we remove to produce realistic performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3286c37a-32ea-4718-9bf5-040a10c46d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv(\"DevData.csv\", dtype={\"id\": \"str\"})\n",
    "dev_data[\"date\"] = pd.to_datetime(dev_data[\"date\"])\n",
    "dev_data = dev_data[(dev_data[\"temperature\"] > -0.5) & (dev_data[\"temperature\"] < 40)]\n",
    "# dev_data[\"day\"] = dev_data[\"date\"].dt.day_of_year\n",
    "# gsamp = pd.read_csv(\"GageSample.csv\",\n",
    "#                    dtype={\"id\": \"str\"})\n",
    "# def idfix(data):\n",
    "#     data = data[data[\"id\"].apply(lambda x: x.startswith(\"USGS\"))]\n",
    "#     data[\"id\"] = data[\"id\"].apply(lambda x: x.split(\"_\")[1])\n",
    "#     return data\n",
    "# lcov = idfix(pd.read_csv(\"LandCover.csv\"))\n",
    "# area = idfix(pd.read_csv(\"Area.csv\"))\n",
    "# topo = idfix(pd.read_csv(\"Topography.csv\"))\n",
    "# dev_data = dev_data.merge(lcov, on=\"id\").merge(area, on=\"id\").merge(topo, on=\"id\").merge(gsamp[[\"id\", \"lat\", \"lon\"]], on=\"id\")\n",
    "# dev_data.to_csv(\"DevData.csv\", index=False)\n",
    "# test_data = whatever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2e368-0a05-4b30-bf90-2e5a059ebc24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Calibrated Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57c0945c-207d-4ecc-82f1-6f1907b4941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_dev(gid, start=None):\n",
    "    idd = dev_data[dev_data[\"id\"] == gid]\n",
    "    if idd[\"temperature\"].mean() > 35 or idd[\"temperature\"].mean() < 0:\n",
    "        return (None, None)  # bad data or major outlier\n",
    "    if start is None:\n",
    "        cut = round(len(idd) * 0.7)\n",
    "        if cut >= 365:\n",
    "            return (idd.iloc[cut:], idd[\"date\"].iloc[cut+1])\n",
    "        else:\n",
    "            return (None, None)  # dataset too small\n",
    "    else:\n",
    "        return idd[idd[\"date\"] >= start]\n",
    "\n",
    "def cal_val(gid, cal_fn = cut_dev, val_fn = cut_dev):\n",
    "    (train, cutoff) = cal_fn(gid)\n",
    "    try:\n",
    "        if cutoff is not None:\n",
    "            test = cal_fn(gid, cutoff)\n",
    "            model = NEWT.Watershed.from_data(train)\n",
    "            return model.run_series(test)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ef967-0fc1-45fc-9232-5d2288be584e",
   "metadata": {},
   "source": [
    "## Hindcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c6d58c13-562f-40cd-9bbe-ea65c3efe70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n",
      "'NoneType' object has no attribute 'generate_ts'\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    preds = pd.concat([cal_val(x) for x in dev_data[\"id\"].unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "58fd9d74-394b-4077-ba54-e7e1c050ed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds[abs(preds[\"anom\"]) < 10]  # I don't know why one of the models is predicting colossal anomalies, but it is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724e66f-a97c-4823-9300-e15047a3a149",
   "metadata": {},
   "source": [
    "Overall performance summary below.  Note that stationarity, in particular, does absurdly well as a comparison point (same temperature today as yesterday).  As far as I'm aware, this comparison has not been run for most previous models.  It would be interesting to see how much of a lag is required for NEWT to outperform stationarity.  This does suggest that, if you have observations, \"same as yesterday\" is probably a better bet than most non-data-assimilating models.\n",
    "\n",
    "Interestingly, when a massive outlier that was predicting anomalies in the thousands of degrees is removed, global performance is very similar to gagewise performance.  Note that huge anomaly sensitivity isn't representative of any real use case, since in a calibrated model that would be corrected for and the (smoothed) coefficient estimation model won't predict such high sensitivity.  (If it did happen, it would be fairly obvious that ~3000 C is not a reasonable estimate.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0dfc610d-303b-4646-ad3a-5a9605097e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               R2        RMSE         NSE  StationaryNSE  ClimatologyNSE  \\\n",
      "count  943.000000  943.000000  943.000000     943.000000      943.000000   \n",
      "mean     0.921120    1.567262    0.919433       0.976682        0.951546   \n",
      "std      0.097137    0.485112    0.100530       0.017775        0.051659   \n",
      "min      0.088175    0.121245    0.080547       0.855635        0.287647   \n",
      "25%      0.920707    1.311004    0.919830       0.969289        0.935658   \n",
      "50%      0.944844    1.529255    0.944183       0.980622        0.958143   \n",
      "75%      0.961753    1.757990    0.960944       0.988834        0.979532   \n",
      "max      0.988151    7.747312    0.987592       0.999138        1.000000   \n",
      "\n",
      "       AnomalyNSE       Pbias        Bias     MaxMiss  \n",
      "count  833.000000  943.000000  943.000000  943.000000  \n",
      "mean     0.152678    0.071368    0.006446    1.292032  \n",
      "std      3.812618    0.761416    0.085490    0.881240  \n",
      "min    -77.248323   -9.045063   -1.071342    0.015025  \n",
      "25%      0.309765   -0.133994   -0.018752    0.677389  \n",
      "50%      0.504666    0.031715    0.004240    1.111317  \n",
      "75%      0.645546    0.213800    0.028365    1.686920  \n",
      "max      0.846076    7.366436    0.553195    7.180226  \n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    print(preds.groupby(\"id\").apply(NEWT.analysis.perf_summary).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13db6a56-de5a-4277-bea5-2f85140fd2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>NSE</th>\n",
       "      <th>StationaryNSE</th>\n",
       "      <th>ClimatologyNSE</th>\n",
       "      <th>AnomalyNSE</th>\n",
       "      <th>Pbias</th>\n",
       "      <th>Bias</th>\n",
       "      <th>MaxMiss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.959498</td>\n",
       "      <td>1.573854</td>\n",
       "      <td>0.959488</td>\n",
       "      <td>0.983768</td>\n",
       "      <td>0.607717</td>\n",
       "      <td>0.902755</td>\n",
       "      <td>0.033256</td>\n",
       "      <td>0.004434</td>\n",
       "      <td>1.905588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         R2      RMSE       NSE  StationaryNSE  ClimatologyNSE  AnomalyNSE  \\\n",
       "0  0.959498  1.573854  0.959488       0.983768        0.607717    0.902755   \n",
       "\n",
       "      Pbias      Bias   MaxMiss  \n",
       "0  0.033256  0.004434  1.905588  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEWT.analysis.perf_summary(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c39592-758d-43b8-b7de-8f4788a55234",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac367f6-da84-4dd2-94e5-6121c42ea262",
   "metadata": {},
   "source": [
    "### HRRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a43c76-40eb-4e2e-b89d-324e57455349",
   "metadata": {},
   "source": [
    "### GFS/GEFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9cc64d-c09b-4f79-a1e3-fd6855650f61",
   "metadata": {},
   "source": [
    "## Heterogeneous Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd8d82-346b-4167-a08b-d8facd4761e7",
   "metadata": {},
   "source": [
    "# Gagewise Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e229432e-f3cb-453b-a3e5-4ee864f8d6b2",
   "metadata": {},
   "source": [
    "Well, something extremely weird is happening with the anomaly predictions.  It's not the coefficients themselves, which are consistently \"sane\" (max sensitivity coefficient is 0.95).  Something weird must be happening with the weather anomaly analysis itself.  The problem is not air temperature dailies, which range from -26 to +40.  So there must be some sort of issue with air temperature itself.  Not that either: observed tmax ranges from -28 to +45.  So what on Earth is going on?\n",
    "\n",
    "Even though tmax is reasonable, the anomaly jumps from a sane 4.1 at the 80.5 percentile to ~600M at 81%.  More precisely, the jump is at about 80.73%.  How on Earth are ~20% of the anomaly predictions suddenly jumping into the millions of degrees?  We know that it's happening for the large majority of watersheds, since even the 75th percentile NSE is solidly negative.  That also implies that the cause is something dynamic.\n",
    "\n",
    "There seem to be two major possibilities:\n",
    "\n",
    "- Threshold engine is going haywire\n",
    "- Convolution is somehow broken\n",
    "\n",
    "It looks like threshold issues could conceivably result if the cutoff and minimum temperatures are quite close.  Let's take a closer look at the coefficients.\n",
    "\n",
    "Some of the gaps are quite small (as low as 0.01), but some erroneous coefficient in the hundreds would not explain predictions in the millions, and regardless, that occurs rarely.  That, in itself, is not the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e73160-3101-4586-a0b3-16db7b0a4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modbuilder: data -> (ws -> prediction)\n",
    "def make_modbuilder(use_clim, lookback):\n",
    "    def next_modbuilder(data):\n",
    "        nx = NEXT.NEXT.from_data(data)\n",
    "        def prd(x):\n",
    "            mod = nx.make_newt(x, reset=True, use_climate=use_clim, climyears=lookback).get_newt()\n",
    "            mod.dynamic_engine = None\n",
    "            return mod.run_series(data)\n",
    "        return prd\n",
    "        # return lambda x: nx.make_newt(x, reset=True, use_climate=use_clim, climyears=lookback).get_newt().coefs_to_df()\n",
    "        # return lambda x: nx.run(x, reset=True, use_climate=use_clim, climyears=lookback)\n",
    "    return next_modbuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdb06b4-b5cf-49ab-a7ac-cb16ec1127ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim=False\n",
    "lookback=5\n",
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    # kfr = NEWT.analysis.kfold(dev_data, make_modbuilder(clim, lookback), output=f\"results/kfold_coefficients{'_withclim_lookback' + str(lookback) if clim else ''}.csv\")\n",
    "    kfr = NEWT.analysis.kfold(dev_data, make_modbuilder(clim, lookback), output=f\"results/kfold_nothreshold.csv\")\n",
    "    # kfr = NEWT.analysis.kfold(dev_data, make_modbuilder(clim, lookback), output=f\"results/kfold{'_withclim_lookback' + str(lookback) if clim else ''}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa72c25-27cc-441f-addb-7dc0fdbe1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfr.groupby(\"id\").apply(NEWT.analysis.perf_summary, include_groups=False).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753c52c5-ace4-40fb-8c42-89ecc2c28acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af4c87-9b15-42cb-be80-33294d9533c6",
   "metadata": {},
   "source": [
    "# Test Set Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db55ca7-2362-4648-b56e-ac592cb8c811",
   "metadata": {},
   "source": [
    "## Hindcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28983ec4-8d52-48d3-99b4-7acff4639f71",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebbbad-2549-43f5-a7f8-1cfdb4868722",
   "metadata": {},
   "source": [
    "### HRRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a2baa-e624-41e0-8590-95d9489b04ef",
   "metadata": {},
   "source": [
    "### GFS/GEFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab620a-a7e3-4be5-a0db-3100e4fca0e8",
   "metadata": {},
   "source": [
    "## Heterogeneous Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06868ceb-75a9-4800-b71f-da5c6102d2e8",
   "metadata": {},
   "source": [
    "# Extrapolation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0540cd1-821b-4f59-a3a9-6220d986b01b",
   "metadata": {},
   "source": [
    "## Regional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd53755-41a6-458c-b9a1-dfa73647b1d6",
   "metadata": {},
   "source": [
    "## Elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042ec30-91dc-45c3-ac82-0ceee3afe2de",
   "metadata": {},
   "source": [
    "## Walk-Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28447fa-3c1e-4964-844d-30f5ed35de83",
   "metadata": {},
   "source": [
    "# Regime Shift/Disturbance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9044da-f998-4c51-a249-89127b458964",
   "metadata": {},
   "source": [
    "# Small Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e830c-c29d-4191-858a-5b95937cee5c",
   "metadata": {},
   "source": [
    "# True Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b5cf30-4621-4144-b0d7-ca981a6f89dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
