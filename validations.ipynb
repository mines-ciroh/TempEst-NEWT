{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0413d1a9-4f94-44d5-af96-68e98e8c153f",
   "metadata": {},
   "source": [
    "# TempEst-NEXT Validation Suite\n",
    "\n",
    "This Notebook provides a standard suite of model tests for TempEst-NEXT.  This serves two purposes:\n",
    "\n",
    "1. Reproducibility of research.  This notebook is used to generate final manuscript figures relating to model performance. The notebook itself is provided with the published model and dataset, allowing exact reproducibility (and easy modification) of the analysis.\n",
    "2. Efficient, consistent testing.  After modifying the model, running this notebook is a quick way to make sure everything still works and to assess performance impacts.\n",
    "\n",
    "For validation, we use two pre-retrieved datasets as well as some automatic retrieval of new data.  The two pre-retrieved datasets are a \"development\" set of ~900 USGS gages (nominally 1,000; 900ish with overlapping data coverage) and a \"test\" set of ~400 (nominal) USGS gages paired with daymet meteorology, 3DEP topography, NLCD land cover, etc.  The development set was used for model development and tuning, while the test set is reserved for final validation (i.e., here).\n",
    "\n",
    "## Assessed Model Characteristics\n",
    "\n",
    "The goal is to assess several model performance characteristics.  Forecasting is used for a handful of tests, but most analysis focuses on hindcasting for computational convenience.  It is assumed that any performance discrepancies in forecasting vs hindcasting would be apparent in the tests that cover both, and thus that not every analysis needs to test forecasting.\n",
    "\n",
    "In this notebook, forecasting is primarily tested by using archived weather forecasts to predict what the forecast would have been for time periods where observations are available, which is necessary for automatic testing.  There is code to run a \"real\" forecast, but this cannot be automatically evaluated because observations are not available, so the user is left to go back and check once observations are available.\n",
    "\n",
    "1. Calibrated model hindcasting and forecasting performance, using TempEst-NEWT like a typical single-watershed model\n",
    "2. General ungaged hindcasting and forecasting performance\n",
    "3. Ungaged-region hindcasting performance\n",
    "4. Ungaged-elevation hindcasting performance\n",
    "5. Ungaged-time-period hindcasting performance\n",
    "6. Disturbance hindcasting performance\n",
    "7. Small-stream hindcasting performance?\n",
    "\n",
    "## Tests\n",
    "\n",
    "The following tests are used to assess the above performance characteristics.\n",
    "\n",
    "- Calibrated testing: train a model on the first 70% of observations for each stream, then evaluate performance for predicting the last 30%.  This uses the development dataset.\n",
    "  - Use meteorology estimates (daymet) for training and testing: hindcast test.  Because the model architecture does not actually use \"today's\" weather (up through yesterday only), this is also a 24-hour forecast test.\n",
    "  - Use weather forecast archives (HRRR, GFS/GEFS) for training and testing: forecast test.  Test forecast periods of 2, 3 (HRRR), 7, 10, 14, 17 (GFS/GEFS) days.  Note forecast period is 1 day *past* the last day of the weather forecast, since NEWT does not depend on day-of weather.\n",
    "  - Use meteorology estimates for training and forecasts for testing: evaluate the impact of heterogeneous datasets.  Use 2-day HRRR-forced forecast only.\n",
    "- Gagewise cross-validation: partition development dataset gages into *k* equal sets.  Train a model on all partitions but one, and evaluate performance for predicting the excluded partition.  This tests general ungaged performance, not accounting for any potential impact of having used the same dataset for model tuning.  Hindcasting (met estimate) only.\n",
    "- Test set validation: train a model on the development set, and evaluate performance for predicting the test set.  This tests general ungaged performance for a fully-independent dataset.\n",
    "  - Meteorology estimates (hindcast)\n",
    "  - Weather forecast archives (forecast) for a range of lead times\n",
    "  - Train on estimates/test on forecasts (forecast with heterogeneous data)\n",
    "- Extrapolation hindcasting tests: partition the combined development and testing sets along some characteristic of interest, and use a model trained on one group to predict the other group.  This tests the ability of TempEst-NEXT to extrapolate in terms of specific characteristics.  All hindcasting.\n",
    "  - Regional: partition the CONUS into contiguous regions and run leave-one-out cross-validation over the regions.\n",
    "  - Elevation: train a model on the lower elevations and predict higher elevations.  Partial dependency plots and previous research suggest there is a major shift in watershed dynamics around 2300 m, and it is difficult to extrapolate past that barrier.\n",
    "  - Time (walk-forward validation): train a model up to a given year, then predict the next year.  This tests whether the model can extrapolate forward in time.\n",
    "- Regime-shift hindcasting: identify a set of watersheds for which the observed thermal regime has shifted significantly.  Train the model on everything else, then try to predict the disturbed watersheds and see how the model performs.  This assesses whether TempEst-NEXT is capable of capturing regime shifts.\n",
    "- Small-stream hindcasting: if possible, use the model to predict temperatures at very small (e.g., first-order headwaters, centimeters to a few meters wide) streams where some observations are available, just to see if it works there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2e368-0a05-4b30-bf90-2e5a059ebc24",
   "metadata": {},
   "source": [
    "# Calibrated Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ef967-0fc1-45fc-9232-5d2288be584e",
   "metadata": {},
   "source": [
    "## Hindcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c39592-758d-43b8-b7de-8f4788a55234",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac367f6-da84-4dd2-94e5-6121c42ea262",
   "metadata": {},
   "source": [
    "### HRRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a43c76-40eb-4e2e-b89d-324e57455349",
   "metadata": {},
   "source": [
    "### GFS/GEFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9cc64d-c09b-4f79-a1e3-fd6855650f61",
   "metadata": {},
   "source": [
    "## Heterogeneous Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd8d82-346b-4167-a08b-d8facd4761e7",
   "metadata": {},
   "source": [
    "# Gagewise Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af4c87-9b15-42cb-be80-33294d9533c6",
   "metadata": {},
   "source": [
    "# Test Set Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db55ca7-2362-4648-b56e-ac592cb8c811",
   "metadata": {},
   "source": [
    "## Hindcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28983ec4-8d52-48d3-99b4-7acff4639f71",
   "metadata": {},
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebbbad-2549-43f5-a7f8-1cfdb4868722",
   "metadata": {},
   "source": [
    "### HRRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a2baa-e624-41e0-8590-95d9489b04ef",
   "metadata": {},
   "source": [
    "### GFS/GEFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab620a-a7e3-4be5-a0db-3100e4fca0e8",
   "metadata": {},
   "source": [
    "## Heterogeneous Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06868ceb-75a9-4800-b71f-da5c6102d2e8",
   "metadata": {},
   "source": [
    "# Extrapolation Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0540cd1-821b-4f59-a3a9-6220d986b01b",
   "metadata": {},
   "source": [
    "## Regional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd53755-41a6-458c-b9a1-dfa73647b1d6",
   "metadata": {},
   "source": [
    "## Elevation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042ec30-91dc-45c3-ac82-0ceee3afe2de",
   "metadata": {},
   "source": [
    "## Walk-Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28447fa-3c1e-4964-844d-30f5ed35de83",
   "metadata": {},
   "source": [
    "# Regime Shift/Disturbance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9044da-f998-4c51-a249-89127b458964",
   "metadata": {},
   "source": [
    "# Small Stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5e830c-c29d-4191-858a-5b95937cee5c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
