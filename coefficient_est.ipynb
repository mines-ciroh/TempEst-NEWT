{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763e071b-0581-4eac-9db8-b0a723a8f11d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Coefficient Estimation for NEWT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028f52e-4fee-4723-9eea-c6c0b55eb37e",
   "metadata": {},
   "source": [
    "The optimal model involves eight seasonality coefficients and a baseline air temperature sensitivity, a total of nine terms.  We don't need to estimate anything for the relationship between seasonal temperature and sensitivity on a given day, since a global GAM does that.  So we have nine coefficients to estimate.\n",
    "\n",
    "However, those nine coefficients are correlated, which raises problems for uncertainty analysis and, in general, suggests inefficiency.  So the first thing we're going to do is principle component analysis on the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a8720-34fc-4ef5-92cc-2005a799a323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas.plotting as pdp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rtseason as rts\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "import pygam  # https://pygam.readthedocs.io/en/latest/notebooks/tour_of_pygam.html\n",
    "from pygam import LinearGAM, s, te, l, f\n",
    "from NEWT import Watershed, kfold, perf_summary, statics, analysis, engines\n",
    "from NEWT.make_coefficients import build_training_data\n",
    "import NEXT.data as ndata\n",
    "import NEWT\n",
    "from math import ceil\n",
    "anomweights = np.array([0.132, 0.401, 0.162, 0.119, 0.056, 0.13 ])\n",
    "bp = \"/scratch/dphilippus/notebooks/next_validation/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eed239-ffb7-49a9-95ba-09db6d8f232b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sillymod: use one generic model.  Otherwise, fit each model to itself.\n",
    "def dummy_modbuilder(data, sillymod):\n",
    "    data = data.groupby(\"date\")[[\"temperature\", \"tmax\", \"vp\"]].mean().assign(date = lambda x: x.index)\n",
    "    def runner(ws):\n",
    "        try:\n",
    "            if sillymod:\n",
    "                return Watershed.from_data(data).run_series(ws)\n",
    "            else:\n",
    "                return Watershed.from_data(ws).run_series(ws)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d03cc4-2a4e-4adc-a4c6-9221dcf67fc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(bp + \"DevDataBuffers.csv\", dtype={\"id\": \"str\"}, parse_dates=[\"date\"])\n",
    "data = data[(data[\"temperature\"] > -0.5) & (data[\"temperature\"] < 40)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29f825-e057-463d-a480-0da4b98d1c06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(columns=\"date\").describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886aaef7-7e4e-4775-b89f-f4da9d30664a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Add Reach Buffer Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83071654-11aa-4570-ac17-b70fc8c88b4f",
   "metadata": {},
   "source": [
    "For each site, we want 1-km-upstream, 15-m-buffer canopy cover and mean direction.  Conveniently, flow direction maps exactly onto slope aspect of the river itself, since by definition it flows precisely downhill.  Runtime depends on period of record, but is currently averaging 15 seconds per site (suggesting ~4 hours for all of them)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "95cfa085-49e1-4ccd-aed5-1302f372bb84",
   "metadata": {
    "tags": []
   },
   "source": [
    "drs = data.groupby(\"id\", as_index=False)[\"date\"].agg([\"min\", \"max\"])  # id, min, max"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8042b003-e8d2-4b51-bfa4-6f07e52ef84f",
   "metadata": {
    "tags": []
   },
   "source": [
    "def proc_buffer(row):\n",
    "    # Row is assumed to be a named tuple with .id, .min, .max.\n",
    "    # Get canopy cover and mean direction.\n",
    "    try:\n",
    "        geom = ndata.get_upstream_buffer(row.id, \"usgs\", 1, 0.015)\n",
    "        fdir = ndata.get_mean_direction(row.id, \"usgs\")\n",
    "        canopy = pd.DataFrame([{\"year\": year, \"canopy\": ndata.get_canopy(geom, str(year))} for year in range(row.min.year, row.max.year + 1)])\n",
    "        canopy[\"flowdir\"] = fdir\n",
    "        canopy[\"id\"] = row.id\n",
    "        print(\"|\", end=\"\")\n",
    "        return canopy\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e410dffe-39b4-47ae-845a-73f8b1e588e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "buffer_path = bp + \"dev_buffers.csv\"\n",
    "if os.path.exists(buffer_path):\n",
    "    buffer_data = pd.read_csv(buffer_path, dtype={\"id\": \"str\"})\n",
    "else:\n",
    "    buffer_data = pd.concat([proc_buffer(row) for row in drs.itertuples()])\n",
    "    buffer_data.to_csv(buffer_path, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3094263-2307-4d56-a9e4-3ce6b35ebc69",
   "metadata": {
    "tags": []
   },
   "source": [
    "data[\"year\"] = data[\"date\"].dt.year\n",
    "data = data.merge(buffer_data, on=[\"id\", \"year\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b375f0e-e0fd-40d2-9d04-434fef79c65a",
   "metadata": {
    "tags": []
   },
   "source": [
    "data.to_csv(bp + \"DevDataBuffers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f16d7-3dc5-4555-b961-28583ed90865",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## A Silly Kfold Test\n",
    "\n",
    "First we need to test the cross-validation setup, so we have a dummy model to test it with.  One option is to use a model that's just trained on everything.  The other option is to use a model that's trained on each watershed to predict itself."
   ]
  },
  {
   "cell_type": "raw",
   "id": "72de6874-1e03-4ff4-9979-b22b1b23c2df",
   "metadata": {},
   "source": [
    "silly = kfold(data, lambda x: dummy_modbuilder(x, True), output=\"results/Silly.csv\")\n",
    "cheat = kfold(data, lambda x: dummy_modbuilder(x, False), output=\"results/Cheat.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5be9e51a-6a3d-4ee5-b922-700bbeb2055e",
   "metadata": {},
   "source": [
    "silly.groupby(\"id\").apply(perf_summary, include_groups=False).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e060a-a135-4494-8b34-9b72f6b23986",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare Coefficients\n",
    "\n",
    "Since the kfold testing seems to be working, let's prepare model coefficients.  To recap, we need to provide seasonality coefficients, tmax and vp sensitivities, and tmax and vp dailies (for static/spin-up).  We can also set up dynamic and yearly modification engines, and will eventually separate estimators into static (at start) and climate/dynamic (through a climate modification engine), but that can come later.\n",
    "\n",
    "A brief test was run and subsequently deleted to establish that simple sinusoid (annual-period, variable-phase sine) does a solid job capturing vp and tmax annual cycles (median R2 0.95 and 0.92, respectively), and therefore those coefficients are suitable here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683d8392-3735-4eae-9006-25d0dbf141ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_coefficients(grp):\n",
    "    if len(grp[\"day\"].unique()) < 181:\n",
    "        return None\n",
    "    anomilized = NEWT.watershed.anomilize(grp).sort_values(\"date\")[[\"date\", \"st_anom\", \"at_anom\"]]  # st_anom, at_anom\n",
    "    ssn = rts.ThreeSine.from_data(grp[[\"day\", \"temperature\"]]).to_df().drop(columns=[\"RMSE\", \"R2\"])\n",
    "    for i in range(6):\n",
    "        anomilized[f\"delta{i}\"] = anomilized[\"at_anom\"].shift(i)\n",
    "    anomilized = anomilized.dropna()\n",
    "    X = anomilized.loc[:, \"delta0\":\"delta5\"]\n",
    "    y = anomilized[\"st_anom\"]\n",
    "    prd = X @ anomweights\n",
    "    ssn[\"sensitivity\"] = y.abs().mean() / prd.abs().mean()\n",
    "    return ssn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9271d-f052-4698-b561-ca61c684a57f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefs = data.groupby(\"id\").apply(make_coefficients, include_groups=False).droplevel(1)\n",
    "coefs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962a3b48-6a0b-46a6-b456-5018b71ae173",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefs.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a5c4ef-faee-4608-aa7b-1355c03ef110",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf45225-8bb3-49ef-baec-56f622c3186b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "offset = coefs.mean()\n",
    "scale = coefs.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86c25a-a2ab-46ff-bebb-2cca9e6f4ace",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "co_norm = (coefs - offset) / scale\n",
    "co_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bebf3a4-85a8-4e14-b72f-06108b2060db",
   "metadata": {},
   "source": [
    "There are some nontrivial cross-correlations, so let's see what the principal component axes look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd04ec8a-a138-47a5-9a65-a024d8cbd69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "fit = pca.fit(co_norm)\n",
    "evr = fit.explained_variance_ratio_\n",
    "print(evr)\n",
    "print(np.cumsum(evr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1abebcb-a92e-4762-a5b2-826653c2ee36",
   "metadata": {},
   "source": [
    "Of the 9 coefficients, we capture 96% of the variance with 8 of them, 92% with 7, 86% with 6, etc.  But that's not the point: we're looking to predict uncorrelated variables, not compress the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b5325-4d17-472a-a34f-8ce0a0a98914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=np.arange(1, len(evr)+1), y=np.cumsum(evr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6d121-9d4a-410d-a326-cc1029aa753a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pcax = pd.DataFrame(fit.components_,\n",
    "            columns=coefs.columns)  # shape: components x features. So a row is a PC and a column is a feature.\n",
    "pcax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863fec5-e1c2-4dde-87c1-00569fbe02fe",
   "metadata": {},
   "source": [
    "So what's actually going into this stuff?  From most important to least:\n",
    "\n",
    "0. Distributed across pretty much everything except Fall, Spring, and Summer days.\n",
    "1. Heavy on the three days omitted before, plus some weight on Intercept, Amplitude, and FallWinter.\n",
    "2. Heavy on SpringDay and sensitivity with some Amplitude.\n",
    "3. Heavy on SpringSummer and Summer, Spring and Fall days\n",
    "4. SummerDay, SpringSummer, and sensitivity\n",
    "5. FallWinter, with a little Fall and Winter days\n",
    "6. Amplitude and FallDay\n",
    "7. WinterDay, SpringDay, and Intercept\n",
    "8. Intercept, SummerDay, and FallWinter\n",
    "\n",
    "Note that all components and all features have roughly equal total absolute weights, just distributed differently.  Total non-absolute weights are quite variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0d32f-e3e6-402d-84af-d58bf01219ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.heatmap(pcax.T.abs(), cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d057ae-8cd4-44ec-b19a-8333c4d30acd",
   "metadata": {},
   "source": [
    "As a sanity check, coefficients x t(PCA) should give us 9 uncorrelated variables.  It works!  And we invert it by multiplying by (non-transposed) PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d7ce41-2d99-4aad-a2e5-7122f3352556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "comps = co_norm @ np.transpose(fit.components_)\n",
    "comps.columns = [f\"pca{x}\" for x in range(9)]\n",
    "comps.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a045d-604d-47a4-a986-6a450e5e0211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3eb56a-dfa3-4201-862a-656b71b92e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coefs_rc = comps @ fit.components_\n",
    "coefs_rc.columns = coefs.columns\n",
    "coefs_rc = coefs_rc * scale + offset\n",
    "coefs_rc - coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86201b67-69ec-4c8a-b157-7ea76ec0a18b",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We'll use a GAM.  This lets us test a broad range of relationships while keeping it quick and interpretable, and has precedent in the literature (PNW from Siegel et al at NOAA Northwestern Fisheries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04750ab5-1016-4945-9066-77860dc1dd6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Generalized Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f52697-7a4c-4e41-8c8a-8295437517f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = NEWT.coef_est.preprocess(data).drop(columns=[\"level_1_x\", \"level_1_y\", \"date\", \"day\"])\n",
    "preds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e862d2d9-cc6d-4347-a196-1b400a90f017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mdata = comps.merge(preds, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19e0fa-5420-43b8-ae85-d2f9626109bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = mdata.iloc[:, 10:]\n",
    "allvar = X.columns\n",
    "Y = mdata.loc[:, \"pca0\":\"pca8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bce63b-82cc-484f-a38c-0d733ea60724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f62cf-89f5-4f53-9c62-ffb6168fcf5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reference linear model\n",
    "Xnp = np.concatenate((np.ones((len(X), 1)), X.to_numpy()), axis=1)\n",
    "lfit = np.linalg.lstsq(Xnp, Y, rcond=None)[0]\n",
    "prd = Xnp @ lfit\n",
    "pd.concat([\n",
    "    pd.DataFrame({\"R2\": np.corrcoef(Y.iloc[:, i], prd[:, i])[0, 1]**2}, index=[Y.columns[i]])\n",
    "    for i in range(len(Y.columns))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4b1650-e2b9-4ed3-8179-5e4d3b707a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "varname = {\n",
    "    'intercept': \"Mean Air Temperature (C)\",\n",
    "    'prcp': \"Mean Precipitation (mm/day)\",\n",
    "    'cold_prcp': \"Mean Subfreezing Precip (mm/day)\",\n",
    "    'frozen': \"Proportion of Days Below Freezing\",\n",
    "    'srad': \"Mean Solar Radiation (W/m2)\",\n",
    "    'water': \"Water Land Cover Fraction\",\n",
    "    'developed': \"Developed Land Cover Fraction\",\n",
    "    'barren': \"Barren Land Cover Fraction\",\n",
    "    'forest': \"Forest Land Cover Fraction\",\n",
    "    'shrubland': \"Shrubland Land Cover Fraction\",\n",
    "    'herbaceous': \"Herbaceous Land Cover Fraction\",\n",
    "    'cultivated': \"Cultivated Land Cover Fraction\",\n",
    "    'wetland': \"Wetland Land Cover Fraction\",\n",
    "    'ice_snow': \"Ice/Snow Land Cover Fraction\",\n",
    "    'canopy': \"Last-km Riparian Canopy Cover (%)\",\n",
    "    'flowdir': \"Mean Last-km Flow Direction (deg)\", \n",
    "    'area': \"Watershed Area (m2)\",\n",
    "    'elev': \"Mean Elevation (m)\",\n",
    "    'elev_min': \"Min Elevation (m)\",\n",
    "    'slope': \"Watershed Mean Slope (m/m)\",\n",
    "    'asp_north': \"Slope Aspect Mean North Component\",\n",
    "    'asp_east': \"Slope Aspect Mean East Component\",\n",
    "    'lat': \"Latitude (deg N)\",\n",
    "    'lon': \"Longitude (deg E)\",\n",
    "    'prcp_sd': \"Std Dev Precipitation (mm/day)\",\n",
    "    'srad_sd': \"Std Dev Solar Radiation (W/m2)\",\n",
    "    'vp': 'Mean Vapor Pressure (Pa)',\n",
    "    'vp_sd': \"Std Dev Vapor Pressure (Pa)\",\n",
    "    'prcp_phi': \"Mean Date of Precip (Julian day)\",\n",
    "    'prcp_index': \"Precip Seasonality Index\",\n",
    "    'tmax': 'Mean Daily Max Air Temp (C)',\n",
    "    'tmax_phi': 'Mean Date of Air Temp (Julian day)',\n",
    "    'tmax_index': 'Air Temp Seasonality Index',\n",
    "    \"Intercept\": \"3S Intercept (C)\",\n",
    "    \"Amplitude\": \"3S Amplitude (C)\",\n",
    "    \"SpringSummer\": \"3S Spring/Summer Coef. (C)\",\n",
    "    \"FallWinter\": \"3S Autumn/Winter Coef. (C)\",\n",
    "    \"SpringDay\": \"3S Spring Date (Julian day)\",\n",
    "    \"SummerDay\": \"3S Summer Date (Julian day)\",\n",
    "    \"FallDay\": \"3S Autumn Date (Julian day)\",\n",
    "    \"WinterDay\": \"3S Winter Date (Julian day)\",\n",
    "    \"sensitivity\": \"Air Temp. Anomaly Sensitivity (C/C)\"\n",
    "}\n",
    "rename = lambda vrs: [varname[v] for v in vrs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c26d9f-2ec9-4ae8-9b6a-363a8ce381d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "After PCA, the best-variable linear performance is much worse, at 0.59.  We'll see how the GAM does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d885d570-870a-4377-a4fe-42eee07a8840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eqmk = lambda N: sum([s(i) for i in range(1, N)], start=s(0))\n",
    "without = lambda l, v: [i for i in l if i != v]\n",
    "\n",
    "def gam_gcv(X, Y, eq, lam):\n",
    "    return LinearGAM(eq, lam=lam).fit(X, Y).statistics_[\"GCV\"]\n",
    "\n",
    "def tune_lam(X, Y, lams, counter=0, tolerance=0.001, maxdepth=100, debug=False):\n",
    "    # Lams: 3 lambda candidates (low, mid, high)\n",
    "    # Tolerance: minimum change in GCV to proceed.\n",
    "    print(\"|\", end=\"\")\n",
    "    eq = eqmk(len(X.columns))\n",
    "    (l, m, r) = lams\n",
    "    left = gam_gcv(X, Y, eq, l)\n",
    "    mid = gam_gcv(X, Y, eq, m)\n",
    "    right = gam_gcv(X, Y, eq, r)\n",
    "    if debug:\n",
    "        print(f\"{l} = {left} | {m} = {mid} | {r} = {right}\")\n",
    "    # First, we compute the improvement, the new set, and the reference\n",
    "    # option.  After that, we'll decide whether to keep iterating.\n",
    "    # Spacing is computed by powers of 10.\n",
    "    if (delta := mid - left) > 0:  # low is good\n",
    "        ref = l\n",
    "        nl = (l/10, l, l * (m/l)**(1/2))\n",
    "    elif (delta := mid - right) > 0:  # high is good\n",
    "        ref = r\n",
    "        nl = (m * (r/m)**(1/2), r, r*10)\n",
    "    else:\n",
    "        delta = mid - min([left, right])\n",
    "        ref = m\n",
    "        nl = (m * (l/m)**(1/2), m, m * (r/m)**(1/2))\n",
    "    # Now we decide whether to proceed or return.\n",
    "    if delta > tolerance and counter < maxdepth:\n",
    "        return tune_lam(X, Y, nl, counter+1, tolerance, maxdepth, debug)\n",
    "    else:\n",
    "        return ref\n",
    "\n",
    "def tune_gcv(varset, lam, gcv, X, Y, tolerance=0.0001, debug=False):\n",
    "    # Iteratively tune a GAM to optimize GCV.  In each round, we optimize lambda and drop one variable.\n",
    "    # Proceed only if we reduce GCV.  Otherwise, return the current arrangement.\n",
    "    varset = varset.copy()\n",
    "    if gcv is None:\n",
    "        gcv = gam_gcv(X[varset], Y, eqmk(len(varset)), lam)\n",
    "    # First pass: tune lambda.\n",
    "    lam = tune_lam(X[varset], Y, (lam/3, lam, lam*3))\n",
    "    # Next: drop one variable.\n",
    "    best_gcv = gcv\n",
    "    best_var = None\n",
    "    if debug:\n",
    "        print(gcv)\n",
    "    for v in varset:\n",
    "        new_vars = without(varset, v)\n",
    "        new_gcv = gam_gcv(X[new_vars], Y, eqmk(len(new_vars)), lam)\n",
    "        if debug:\n",
    "            print(v, new_gcv)\n",
    "        if new_gcv < best_gcv:\n",
    "            best_gcv = new_gcv\n",
    "            best_var = v\n",
    "    if best_var is None or gcv - best_gcv < tolerance:\n",
    "        return (varset, lam, gcv)\n",
    "    else:\n",
    "        varset.remove(best_var)\n",
    "        print(f\"Lambda: {lam:.2f} | Dropped: {best_var} | GCV: {best_gcv:.4f}\")\n",
    "        return tune_gcv(varset, lam, best_gcv, X, Y, tolerance)\n",
    "\n",
    "def pca_pdps(gams, savebase, do_x=True, Npca=9, pca=fit.components_, scale=scale, offset=offset, cols=coefs.columns,\n",
    "            rtn=False, hgt=3):\n",
    "    \"\"\"\n",
    "    Generate PDPs, then invert PCA so they correspond to actual coefficients.\n",
    "    Save resulting PDPs by y and by x in savebase.\n",
    "    GAMs should be a list of tuples: (gam, x names, simple x names, PCA index)\n",
    "    GAMs must be in order of PCA.\n",
    "    \n",
    "    How does the math work?\n",
    "    A given PC corresponds to a variety of coefficients.\n",
    "    If we multiply one X-PC (single column) by the corresponding PCA row,\n",
    "    we get the contribution of that X, to that PC, distributed across all relevant Y.\n",
    "    Now, if we take every PC-PDP for that X (with zeroes where NA) and multiply\n",
    "    by the PCAs, we get the total contribution of that X to every Y.\n",
    "    That makes a data frame of nX * nY.\n",
    "    If we concatenate those together, we can group them by X or Y, and generate plots accordingly.\n",
    "    \n",
    "    To do that, we first have to extract X/PC pairs from all the PDPs.\n",
    "    \n",
    "    This is modified from pdps_by_x.\n",
    "    \n",
    "    Run separately with do_x=True (by-X) and False (by-Y) to avoid running out of memory.\n",
    "    \n",
    "    If rtn is True, it will just return the first plot, for debugging purposes.\n",
    "    \"\"\"\n",
    "    xes = {}\n",
    "    for (gam, xns, sxns, index) in gams:\n",
    "        terms = [t for t in gam.terms if not t.isintercept]\n",
    "        for (i, sxn) in enumerate(sxns):\n",
    "            if not sxn in xes:\n",
    "                xes[sxn] = {\"xlab\": xns[i], \"ys\": []}\n",
    "            gxg = gam.generate_X_grid(term=i, n=100)\n",
    "            X = gxg[:, terms[i].feature]\n",
    "            pdep = gam.partial_dependence(term=i, X=gxg)\n",
    "            xes[sxn][\"ys\"].append((\n",
    "                index, X, pdep\n",
    "            ))\n",
    "    # Now we have a dictionary {simple x name: {\"xlab\", \"ys\": [(index, X, Y)]}}.  Hopefully the X are always the same?\n",
    "    results = []\n",
    "    for (sxn, vals) in xes.items():\n",
    "        xlab = vals[\"xlab\"]\n",
    "        yinfo = vals[\"ys\"]\n",
    "        ref_x = yinfo[0][1]\n",
    "        Y = np.zeros((len(ref_x), Npca))\n",
    "        for yset in yinfo:\n",
    "            if not (yset[1] == ref_x).all():\n",
    "                raise ValueError(f\"Mismatched X grids!  {sxn}, {yset[0]}\")\n",
    "            Y[:, yset[0]] = yset[2]\n",
    "        # Now we have an X column (ref_x) and a Y matrix.\n",
    "        # Don't add offset, because we just want partial dependency.\n",
    "        Y_adj = pd.DataFrame(Y @ pca, columns=cols) * scale\n",
    "        df = pd.concat([pd.Series(ref_x, name=\"X\"), Y_adj], axis=1)\n",
    "        df[\"X_name\"] = xlab\n",
    "        df[\"sxn\"] = sxn\n",
    "        results.append(df)\n",
    "    results = pd.concat(results)\n",
    "    # Now results is a data frame with X, [ys...], X_name, sxn\n",
    "    # Plots by X variable.\n",
    "    if do_x:\n",
    "        for sxn, df in results.groupby(\"sxn\"):\n",
    "            xname = df[\"X_name\"].iloc[0]\n",
    "            ynames = df.columns[1:]\n",
    "            fig = sns.relplot(df.melt(id_vars=[\"X\", \"X_name\", \"sxn\"]), x=\"X\", y=\"value\",\n",
    "                              col=\"variable\", col_wrap=3, facet_kws={\"sharey\": False},\n",
    "                              kind=\"line\", height=hgt)\n",
    "            fig.set_xlabels(xname)\n",
    "            for ax in fig.axes:\n",
    "                vn = varname[ax.title.get_text().split(\" = \")[1]]\n",
    "                ax.set_ylabel(vn)\n",
    "                ax.set_title(\"\")\n",
    "            if rtn:\n",
    "                return fig\n",
    "            fig.savefig(savebase + f\"X_{sxn}.png\", dpi=1000)\n",
    "            plt.close()\n",
    "    # Plots by Y variable.\n",
    "    else:\n",
    "        for syn, df in results.melt(id_vars=[\"X\", \"X_name\", \"sxn\"]).groupby(\"variable\"):\n",
    "            yname = varname[syn]\n",
    "            # N = len(df[\"X_name\"].unique())\n",
    "            # wrap = int(np.sqrt(N)) + 1\n",
    "            wrap = 4\n",
    "            fig = sns.relplot(df, x=\"X\", y=\"value\", col=\"X_name\", col_wrap=wrap,\n",
    "                              facet_kws={\"sharex\": False}, kind=\"line\", height=hgt)\n",
    "            fig.set_ylabels(yname)\n",
    "            for ax in fig.axes:\n",
    "                vn = ax.title.get_text().split(\" = \")[1]\n",
    "                ax.set_xlabel(vn)\n",
    "                ax.set_title(\"\")\n",
    "            if rtn:\n",
    "                return fig\n",
    "            fig.savefig(savebase + f\"Y_{syn}.png\", dpi=1000)\n",
    "            plt.close()\n",
    "    \n",
    "def pdps(gam, xy0=True, names=None, ylab=None, save=None):\n",
    "    nt = len(gam.terms) - 1\n",
    "    Ny = 1 if nt < 3 else (2 if nt < 9 else 3)\n",
    "    Nx = nt // Ny + (1 if nt % Ny > 0 else 0)\n",
    "    _, axes = plt.subplots(Ny, Nx, figsize=(12,8))\n",
    "    for i, term in enumerate(gam.terms):\n",
    "        if term.isintercept:\n",
    "            continue\n",
    "        ax = axes[i // Nx, i % Nx] if Ny > 1 else axes[i]\n",
    "        if i == 0 and xy0:\n",
    "            XX = gam.generate_X_grid(term=i, meshgrid=True)\n",
    "            Z = gam.partial_dependence(term=1, X=XX, meshgrid=True)\n",
    "            co = ax.contourf(XX[1], XX[0], Z)\n",
    "            \n",
    "        else:\n",
    "            XX = gam.generate_X_grid(term=i)\n",
    "            pdep, confi = gam.partial_dependence(term=i, X=XX, width=0.95)\n",
    "    \n",
    "            ax.plot(XX[:, term.feature], pdep)\n",
    "            ax.plot(XX[:, term.feature], confi, c='r', ls='--')\n",
    "        ax.set_xlabel(repr(term) if names is None else names[i])\n",
    "        if ylab is not None and i % Nx == 0:\n",
    "            ax.set_ylabel(ylab)\n",
    "    plt.tight_layout()\n",
    "    if save is not None:\n",
    "        plt.savefig(bp + save)\n",
    "\n",
    "        \n",
    "def pdps_by_x(named_gams, savebase):\n",
    "    # Generate PDPs, as above, but by x-variable, not y-variable.\n",
    "    # named_gams should be a list of tuples: (gam, xnames, simple_xnames, yname).\n",
    "    # They will be saved as savebase + simple_xname + .png.\n",
    "    xes = {}\n",
    "    for (gam, xns, sxns, yn) in named_gams:\n",
    "        terms = [t for t in gam.terms if not t.isintercept]\n",
    "        for (i, sxn) in enumerate(sxns):\n",
    "            if not sxn in xes:\n",
    "                xes[sxn] = {\"xlab\": xns[i], \"ys\": []}\n",
    "            gxg = gam.generate_X_grid(term=i)\n",
    "            X = gxg[:, terms[i].feature]\n",
    "            pdep, confi = gam.partial_dependence(term=i, X=gxg, width=0.95)\n",
    "            xes[sxn][\"ys\"].append((\n",
    "                yn, X, pdep, confi\n",
    "            ))\n",
    "    for (sxn, vals) in xes.items():\n",
    "        ys = vals[\"ys\"]\n",
    "        nt = len(ys)\n",
    "        nrow = int(nt ** 0.5)\n",
    "        ncol = ceil(nt / nrow)\n",
    "        _, axes = plt.subplots(nrow, ncol, figsize=(12, 8))\n",
    "        for (i, Y) in enumerate(ys):\n",
    "            ax = axes[i // ncol, i % ncol] if nrow > 1 else axes[i] if nt > 1 else axes\n",
    "            xs = Y[1]\n",
    "            ax.plot(xs, Y[2])\n",
    "            ax.plot(xs, Y[3], c='r', ls='--')\n",
    "            ax.set_ylabel(Y[0])\n",
    "            if i // ncol == nrow - 1:\n",
    "                ax.set_xlabel(vals[\"xlab\"])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(savebase + sxn + \".png\", dpi=1200)\n",
    "\n",
    "def get_pd(gam, n):\n",
    "    XX = gam.generate_X_grid(term=n)\n",
    "    y = gam.partial_dependence(term=n, X=XX)\n",
    "    return (XX[:,n], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb3bbb1-818f-4d48-8d21-3e1946aefc20",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868aa695-1cb0-4766-84e4-5b08f464ea9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var0, lam0, gcv0) = tune_gcv(list(allvar), 10, None, X, Y[\"pca0\"])\n",
    "print(var0, lam0, gcv0)\n",
    "eq0 = eqmk(len(var0))\n",
    "gam0 = LinearGAM(eq0, lam=lam0).fit(X[var0], Y[\"pca0\"])\n",
    "gam0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e671165-86a2-41dc-ab1c-a9a6a0eb918f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam0, False, rename(var0), \"PCA 0\", \"results/PCA_PDPs/GAM0.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca06f647-0234-431e-9f50-8d0974b52591",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9054c668-b4d2-461a-b7f8-4a94fc478057",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var1, lam1, gcv1) = tune_gcv(list(allvar), 10, None, X, Y[\"pca1\"])\n",
    "print(var1, lam1, gcv1)\n",
    "eq1 = eqmk(len(var1))\n",
    "gam1 = LinearGAM(eq1, lam=lam1).fit(X[var1], Y[\"pca1\"])\n",
    "gam1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69927c57-e039-44ba-8d5f-815dae7fb751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam1, False, rename(var1), \"PCA 1\", \"results/PCA_PDPs/GAM1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b07715-cf35-4970-9278-9f5593b6e94d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bfba44-fcd6-439b-9f0a-f0f2595f92ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var2, lam2, gcv2) = tune_gcv(list(allvar), 12, None, X, Y[\"pca2\"])\n",
    "print(var2, lam2, gcv2)\n",
    "eq2 = eqmk(len(var2))\n",
    "gam2 = LinearGAM(eq2, lam=lam2).fit(X[var2], Y[\"pca2\"])\n",
    "gam2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6196a1-18fb-425f-8b65-cb1259b7ceea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam2, False, rename(var2), \"PCA 2\", \"results/PCA_PDPs/GAM2.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8c1b0-82f5-4b6f-bdd7-d1bf1743aa2f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2a1e1-75ff-461f-83e8-1288ae4a5196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var3, lam3, gcv3) = tune_gcv(list(allvar), 10, None, X, Y[\"pca3\"])\n",
    "print(var3, lam3, gcv3)\n",
    "eq3 = eqmk(len(var3))\n",
    "gam3 = LinearGAM(eq3, lam=lam3).fit(X[var3], Y[\"pca3\"])\n",
    "gam3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0519a17c-6e81-4e51-a73a-539a40a46544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam3, False, rename(var3), \"PCA 3\", \"results/PCA_PDPs/GAM3.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b41cb-af38-4809-9b63-7d80f421f1f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PCA4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda195d2-d5d2-403b-a989-509d479a24c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var4, lam4, gcv4) = tune_gcv(list(allvar), 10, None, X, Y[\"pca4\"])\n",
    "print(var4, lam4, gcv4)\n",
    "eq4 = eqmk(len(var4))\n",
    "gam4 = LinearGAM(eq4, lam=lam4).fit(X[var4], Y[\"pca4\"])\n",
    "gam4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442583e9-83c6-4864-a07e-bc0f11e55cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam4, False, rename(var4), \"PCA 4\", \"results/PCA_PDPs/GAM4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e7e9b-924c-4fda-a8fd-218ac6dd2a33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771917fd-f146-4522-b6cf-594f68a1b0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var5, lam5, gcv5) = tune_gcv(list(allvar), 10, None, X, Y[\"pca5\"])\n",
    "print(var5, lam5, gcv5)\n",
    "eq5 = eqmk(len(var5))\n",
    "gam5 = LinearGAM(eq5, lam=lam5).fit(X[var5], Y[\"pca5\"])\n",
    "gam5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77068820-36cb-4f56-9e04-95079ba280d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam5, False, rename(var5), \"PCA 5\", \"results/PCA_PDPs/GAM5.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1fb3ee-7fa3-43ea-9976-e4ce70c42661",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62e945-a503-45c2-a1ac-3e5b4f6c24da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var6, lam6, gcv6) = tune_gcv(list(allvar), 10, None, X, Y[\"pca6\"])\n",
    "print(var6, lam6, gcv6)\n",
    "eq6 = eqmk(len(var6))\n",
    "gam6 = LinearGAM(eq6, lam=lam6).fit(X[var6], Y[\"pca6\"])\n",
    "gam6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d443a-e9e5-4cb8-8d4c-afe8af0bee6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam6, False, rename(var6), \"PCA 6\", \"results/PCA_PDPs/GAM6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c3415b-1bdf-41b4-84ce-91e31cda9188",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f6719-8cf8-4e57-8269-7a1286e49ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var7, lam7, gcv7) = tune_gcv(list(allvar), 10, None, X, Y[\"pca7\"])\n",
    "print(var7, lam7, gcv7)\n",
    "eq7 = eqmk(len(var7))\n",
    "gam7 = LinearGAM(eq7, lam=lam7).fit(X[var7], Y[\"pca7\"])\n",
    "gam7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb4c30-ed5c-4198-80d3-97bfa928a75e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam7, False, rename(var7), \"PCA 7\", \"results/PCA_PDPs/GAM7.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728cb28-c1e6-428f-b5d1-019b5f8ed2e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## PCA8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12268586-ab0a-47d2-9e08-8ac4d4177620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(var8, lam8, gcv8) = tune_gcv(list(allvar), 10, None, X, Y[\"pca8\"])\n",
    "print(var8, lam8, gcv8)\n",
    "eq8 = eqmk(len(var8))\n",
    "gam8 = LinearGAM(eq8, lam=lam8).fit(X[var8], Y[\"pca8\"])\n",
    "gam8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70a07c3-5e3a-47f9-baac-562bdcf4088b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pdps(gam8, False, rename(var8), \"PCA 8\", \"results/PCA_PDPs/GAM8.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c106f3d-69fa-45fe-99f4-1f6010c554aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot GAMs By XVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e7d5c-122b-4701-9641-735d5736065d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (gam, xnames, simple_xnames, yname)\n",
    "savebase = bp + \"results/PCA_PDPs/PDPbyX_\"\n",
    "allgams = [\n",
    "    (gam0, rename(var0), var0, \"PCA0\"),\n",
    "    (gam1, rename(var1), var1, \"PCA1\"),\n",
    "    (gam2, rename(var2), var2, \"PCA2\"),\n",
    "    (gam3, rename(var3), var3, \"PCA3\"),\n",
    "    (gam4, rename(var4), var4, \"PCA4\"),\n",
    "    (gam5, rename(var5), var5, \"PCA5\"),\n",
    "    (gam6, rename(var6), var6, \"PCA6\"),\n",
    "    (gam7, rename(var7), var7, \"PCA7\"),\n",
    "    (gam8, rename(var8), var8, \"PCA8\")\n",
    "]\n",
    "pdps_by_x(allgams, savebase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b22369-8fbc-41a1-ab75-13d1b8e34f71",
   "metadata": {},
   "source": [
    "## Plot Reconstructed GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17484709-5251-4ce5-a780-5b1fa8e5e0a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "savebase = bp + \"results/PCA_PDPs/RxcPDPs_\"\n",
    "allgams = [\n",
    "    (gam0, rename(var0), var0, 0),\n",
    "    (gam1, rename(var1), var1, 1),\n",
    "    (gam2, rename(var2), var2, 2),\n",
    "    (gam3, rename(var3), var3, 3),\n",
    "    (gam4, rename(var4), var4, 4),\n",
    "    (gam5, rename(var5), var5, 5),\n",
    "    (gam6, rename(var6), var6, 6),\n",
    "    (gam7, rename(var7), var7, 7),\n",
    "    (gam8, rename(var8), var8, 8)\n",
    "]\n",
    "pca_pdps(allgams, savebase, do_x=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b1165-f824-4525-8a9e-a48a99d46898",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Print GAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d64f2f-3152-49e1-8437-880f67e4273a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this to build list...\n",
    "print(\"var_sets = [\")\n",
    "# for (vr, nm) in [(\"itx\", \"Intercept\"), (\"amp\", \"Amplitude\"), (\"ssu\", \"SpringSummer\"),\n",
    "#                  (\"fw\", \"FallWinter\"), (\"spd\", \"SpringDay\"), (\"sud\", \"SummerDay\"),\n",
    "#                  (\"fad\", \"FallDay\"), (\"wid\", \"WinterDay\"),\n",
    "#                  # (\"atc\", \"at_coef\")\n",
    "#                  (\"tcmax\", \"threshold_coef_max\"), (\"tcmin\", \"threshold_coef_min\"), (\"tcc\", \"threshold_act_cutoff\")\n",
    "#                 ]:\n",
    "for pca in range(9):\n",
    "    vr = str(pca)\n",
    "    nm = \"PCA\" + vr\n",
    "    vrs = eval(\"var\" + vr)\n",
    "    eq = eval(\"eq\" + vr)\n",
    "    lam = eval(\"lam\" + vr)\n",
    "    print(f'    {{\"name\": \"{nm}\", \"vars\": {vrs}, \"eq\": {eq}, \"lam\": {lam:.0f}}},')\n",
    "    # print(f\"var_{vr} = {eval('var_' + vr)}\")\n",
    "    # print(f\"eq_{vr} = {eval('eq_' + vr)}\")\n",
    "    # print(f\"lam_{vr} = {eval('lam_' + vr)}\")\n",
    "print(\"]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b98c8-ac9d-40d2-8d8f-c82e6562ec94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cross-Validation Test\n",
    "\n",
    "Right, we've got some approaches laid out.  Let's test it!  Export the GAM setups and hop over to the validation notebook."
   ]
  },
  {
   "cell_type": "raw",
   "id": "315e4f10-9bd9-490d-8545-729df3203df5",
   "metadata": {
    "tags": []
   },
   "source": [
    "var_sets = [\n",
    "    {\"name\": \"PCA0\", \"vars\": ['tmax', 'elev', 'forest', 'wetland', 'water', 'cold_prcp', 'vp_sd', 'tmax_phi'], \"eq\": s(0) + s(1) + l(2) + s(3) + s(4) + l(5) + s(6) + l(7), \"lam\": 3},\n",
    "    {\"name\": \"PCA1\", \"vars\": ['srad', 'vp', 'elev_min', 'elev', 'slope', 'forest', 'wetland', 'ice_snow', 'water', 'frozen', 'prcp_sd', 'vp_sd', 'tmax_phi', 'tmax_index'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + l(5) + s(6) + s(7) + s(8) + s(9) + l(10) + l(11) + s(12) + l(13), \"lam\": 3},\n",
    "    {\"name\": \"PCA2\", \"vars\": ['elev_min', 'elev', 'forest', 'wetland', 'water', 'canopy', 'frozen', 'cold_prcp', 'vp_sd', 'prcp_phi', 'prcp_index'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10), \"lam\": 3},\n",
    "    {\"name\": \"PCA3\", \"vars\": ['tmax', 'prcp', 'srad', 'vp', 'elev_min', 'elev', 'forest', 'ice_snow', 'water', 'prcp_sd', 'srad_sd', 'vp_sd', 'prcp_phi', 'prcp_index'], \"eq\": s(0) + l(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13), \"lam\": 0.3},\n",
    "    {\"name\": \"PCA4\", \"vars\": ['prcp', 'area', 'elev_min', 'elev', 'slope', 'wetland', 'developed', 'water', 'lat', 'lon', 'frozen', 'cold_prcp', 'prcp_sd', 'vp_sd', 'prcp_index'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14), \"lam\": 1},\n",
    "    {\"name\": \"PCA5\", \"vars\": ['tmax', 'vp', 'elev', 'wetland', 'ice_snow', 'water', 'lon', 'frozen', 'cold_prcp', 'prcp_phi', 'prcp_index', 'tmax_phi', 'tmax_index'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12), \"lam\": 10},\n",
    "    {\"name\": \"PCA6\", \"vars\": ['tmax', 'vp', 'elev_min', 'elev', 'slope', 'forest', 'water', 'canopy', 'frozen', 'prcp_sd', 'vp_sd', 'prcp_index'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11), \"lam\": 10},\n",
    "    {\"name\": \"PCA7\", \"vars\": ['tmax', 'vp', 'area', 'elev_min', 'elev', 'forest', 'developed', 'lat', 'vp_sd'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8), \"lam\": 2},\n",
    "    {\"name\": \"PCA8\", \"vars\": ['tmax', 'prcp', 'vp', 'area', 'elev_min', 'elev', 'slope', 'wetland', 'ice_snow', 'frozen', 'prcp_sd', 'vp_sd', 'tmax_index'], \"eq\": s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12), \"lam\": 1},\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecbb1e95-bd86-403c-b99f-c034a01dfd22",
   "metadata": {},
   "source": [
    "shared = list(set(sum([v[\"vars\"] for v in var_sets], start=[])))\n",
    "# shared = ['atmax', 'ssn_index', 'vp', 'prcp_sd', 'ssn_phi', 'tamp', 'elev', 'srad', 'water', 'prcp', 'Intercept', 'Amplitude', 'atmin', 'intercept', 'srad_sd', 'slope', 'frozen', 'cold_prcp', 'forest']\n",
    "names = [\"Intercept\", \"Amplitude\", \"SpringSummer\", \"FallWinter\", \"SpringDay\", \"SummerDay\", \"FallDay\", \"WinterDay\",\n",
    "         # \"at_coef\"\n",
    "         \"threshold_coef_max\", \"threshold_coef_min\", \"threshold_act_cutoff\"\n",
    "        ]\n",
    "allvar = list(set(shared + names))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9471edcc-d799-46ea-b8ce-16fcd6243bc2",
   "metadata": {},
   "source": [
    "# gam_data = data[[\"id\", \"date\", \"day\", \"tmax\", \"temperature\"]].merge(pds[shared + names + [\"id\"]], on=\"id\")\n",
    "# gam_data.to_csv(\"GAMData.csv\", index=False)\n",
    "gam_data = pd.read_csv(\"GAMData.csv\", dtype={\"id\": \"str\"})\n",
    "gam_data[\"date\"] = pd.to_datetime(gam_data[\"date\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5257729f-01b5-40d9-8a52-b637643f900b",
   "metadata": {},
   "source": [
    "def gam_modbuilder(data):\n",
    "    vars_local = var_sets.copy()\n",
    "    print(\"preparing data\", end=\" | \")\n",
    "    idd = data.groupby(\"id\")[allvar].mean()\n",
    "    # builder = lambda eq, lamd, cols, yn, cd=idd: LinearGAM(eq, lam=lamd).fit(cd[cols], cd[yn])\n",
    "    predictor = lambda cols, gam, ws: gam.predict(ws[cols])[0]\n",
    "    print(\"Training models\", end=\" | \")\n",
    "    for vs in vars_local:\n",
    "        cd = idd if not vs[\"name\"] in [\"threshold_coef_min\", \"threshold_act_cutoff\"] else idd[idd[\"threshold_act_cutoff\"] > -1]\n",
    "        vs[\"gam\"] = LinearGAM(vs[\"eq\"], lam=vs[\"lam\"]).fit(cd[vs[\"vars\"]], cd[vs[\"name\"]])\n",
    "    print(\"Trained models\")\n",
    "    def runner(ws):\n",
    "        # print(f\"Running {ws['id'].iloc[0]}\")\n",
    "        # try:\n",
    "        at_day = ws.groupby([\"day\"], as_index=False)[\"tmax\"].mean().rename(columns={\"tmax\": \"mean_tmax\"})\n",
    "        statics = ws[shared].mean().to_frame().T\n",
    "        for vs in vars_local:  # Essential: sensitivity stuff is LAST - it uses Intercept, Amplitude\n",
    "            statics[vs[\"name\"]] = predictor(vs[\"vars\"], vs[\"gam\"], statics)\n",
    "        ssn = rts.ThreeSine(\n",
    "            Intercept=statics[\"Intercept\"].iloc[0],\n",
    "            Amplitude=statics[\"Amplitude\"].iloc[0],\n",
    "            SpringSummer=statics[\"SpringSummer\"].iloc[0],\n",
    "            FallWinter=statics[\"FallWinter\"].iloc[0],\n",
    "            SpringDay=statics[\"SpringDay\"].iloc[0],\n",
    "            SummerDay=statics[\"SummerDay\"].iloc[0],\n",
    "            FallDay=statics[\"FallDay\"].iloc[0],\n",
    "            WinterDay=statics[\"WinterDay\"].iloc[0]\n",
    "        )\n",
    "        min_temp = ssn.generate_ts()[\"actemp\"].min()\n",
    "        min_temp = min_temp if min_temp > 0 else 0\n",
    "        model = Watershed(seasonality=ssn,\n",
    "                          at_coef=statics[\"threshold_coef_max\"].iloc[0],\n",
    "                          # at_coef=statics[\"at_coef\"].iloc[0],\n",
    "                          at_day=at_day,\n",
    "                          dynamic_period=7,\n",
    "                          dynamic_engine=engines.ThresholdSensitivityEngine(\n",
    "                              act_min=min_temp,\n",
    "                              coef_min=statics[\"threshold_coef_min\"].iloc[0],\n",
    "                              act_cutoff=statics[\"threshold_act_cutoff\"].iloc[0],\n",
    "                              coef_max=statics[\"threshold_coef_max\"].iloc[0]\n",
    "                          )\n",
    "                         )\n",
    "        return model.run_series(ws)\n",
    "        # except Exception as e:\n",
    "        #     print(e)\n",
    "    return runner"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00c09753-8755-4af7-a1db-3e18eaa6ea62",
   "metadata": {},
   "source": [
    "gam_data = None\n",
    "kfr = kfold(gam_data, gam_modbuilder, output=\"results/SmarterGAM_th.csv\", redo=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2ab508d-3394-4e6e-b790-452f47a9315b",
   "metadata": {},
   "source": [
    "perf_summary(kfr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1839b8e-9400-4f76-b4e9-d2d007f19b40",
   "metadata": {},
   "source": [
    "kfr.groupby(\"id\").apply(perf_summary, include_groups=False).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf1e36-d5ef-4a34-a5a4-ac05d54debd9",
   "metadata": {},
   "source": [
    "Oddly, the \"smart GAMs\" are doing slightly worse than the \"naive GAMs\", though global R2 is much better.  Mainly, RMSE is marginally higher (2.3 vs 2.2 C median).  The plots show the usual mix of some near-perfect fits and some wildly off, with everything in between.\n",
    "\n",
    "One possibility is that the relatively high lambdas, or likewise the aggressive paring-down, hinder cross-validation performance.  Performance characteristics shown suggest that the amplitude terms or the weather sensitivity may be faring poorly.  It's also possible that the intercept-normalizing of the amplitude coefficients was a net negative.\n",
    "\n",
    "Allowing more flexibility helped but did not fully address the problem.  Likewise for non-normalizing.\n",
    "\n",
    "I do wonder if the threshold behavior might be hurting rather than helping, since it seems rather hard to predict threshold coefficients.  The last resort would be that we really need the point-area data.\n",
    "\n",
    "Excluding thresholds makes performance worse, though it does make the model ~3x faster.  The other last resort is to see what happens if we do include elevation.\n",
    "\n",
    "Or, I may have been too aggressive about excluding covariates.\n",
    "\n",
    "- Initial test: R2 0.94 (global 0.86), RMSE 2.3 (2.9) C, NSE 0.88 (0.86), bias 2.8% (2.0%) = 0.34 (0.26) C, max miss 3.0 (14.1) C\n",
    "- More flexible: R2 0.94 (0.86), RMSE 2.3 (2.9) C, NSE 0.88 (0.86), bias 2.1% (2.0%) = 0.27 (0.27) C, max miss 2.9 (12.3) C\n",
    "- Non-normalized: R2 0.94 (0.87), RMSE 2.3 (2.8) C, NSE 0.88, bias 2.5% (1.9%) = 0.35 (0.25) C, max miss 3.0 (12.2) C\n",
    "- No threshold: R2 0.94 (0.87), RMSE 2.3 (2.8) C, NSE 0.88 (0.87), bias 2.6% (2.0%) = 0.35 (0.26) C, max miss 3.3 (12.3) C\n",
    "- Smarter GAMs (with threshold): R2 0.94 (0.88), RMSE 2.1 (2.7) C, NSE 0.90 (0.88), bias 2.2% (2.0%) = 0.29 (0.26) C, max miss 3.0 (9.3) C\n",
    "\n",
    "Now we're talking!  And the major problem does seem to be anomaly prediction, but this version is good enough for now.\n",
    "\n",
    "The anomaly NSE is actually surprisingly good, at 0.50 (better than TE2, oddly), but, oddly, that's worse than stationary (\"same as yesterday\").  In TempEst 2, stationary NSE was ~0.2.  Not sure what happened there.  Though, of course, for ungaged watersheds we don't *have* an observation for yesterday, so it's still an improvement and considerably better than climatology (NSE = 0)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8af13d3-734b-4b4e-af36-00cfb1c69523",
   "metadata": {},
   "source": [
    "rng = np.random.default_rng()\n",
    "ids = rng.choice(kfr[\"id\"].unique(), 8)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a52a74ee-f956-49fa-8c64-605b9fafb0a3",
   "metadata": {},
   "source": [
    "Ny = 2\n",
    "Nx = 4\n",
    "fig, axes = plt.subplots(Ny, Nx, figsize=(13, 8), sharey=True)\n",
    "for i, ID in enumerate(ids):\n",
    "    ax = axes[i // Nx, i % Nx]\n",
    "    dat = kfr[kfr[\"id\"] == ID]\n",
    "    if len(dat) > 1100:\n",
    "        start = rng.integers(0, len(dat) - 1000)\n",
    "        dat = dat.iloc[start:(start + 1000), :]\n",
    "    dat.plot(x=\"date\", y=\"temperature\", label=\"Observed\", ax=ax)\n",
    "    dat.plot(x=\"date\", y=\"temp.mod\", label=\"Modeled\", ax=ax)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_title(ID)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.supxlabel(\"Date\")\n",
    "_ = fig.supylabel(\"Daily Mean Temperature (C)\")\n",
    "\n",
    "plt.savefig(\"results/SmarterGAMSample.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a25d2e7-c9c8-4e89-8a72-ee4e95511d32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "next",
   "language": "python",
   "name": "next"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
